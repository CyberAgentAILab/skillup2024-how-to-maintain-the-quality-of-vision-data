import{o as r,c as a,k as n,e as t,q as i,s as _,B as e}from"./modules/vue-Bl10Un54.js";import{I as u}from"./slidev/default-DQ1Nlk6D.js";import{u as c,f as m}from"./slidev/context-Cg_4XOdT.js";import{_ as p}from"./index-Bags8cTQ.js";import"./modules/shiki-Bn_9foU7.js";const d="/assets/0023_mAP-DfA9o9aL.png",f={__name:"slides.md__slidev_6",setup(x){const{$slidev:$,$nav:k,$clicksContext:o,$clicks:v,$page:g,$renderContext:B,$frontmatter:l}=c();return o.setup(),(C,s)=>(r(),a(u,i(_(e(m)(e(l),5))),{default:n(()=>s[0]||(s[0]=[t("h1",null,"データ品質を限界まで高めた結果（数値性能）",-1),t("h2",null,null,-1),t("ul",null,[t("li",null,"人間でも視認が難しい極小の人体パーツでも実用的な検出精度を出せる"),t("li",null,"従来困難と思い込まれがちな「属性」も高精度に推定可能"),t("li",null,"頭部向き８方向（front 〜 left-front）のようにテクスチャだけでは判断が困難なクラスも推定可能")],-1),t("img",{src:d,style:{width:"67%",display:"block",margin:"auto"}},null,-1)])),_:1},16))}},A=p(f,[["__scopeId","data-v-c642705e"]]);export{A as default};
